#  YouTube AI Assistant â€” Telegram Bot

An AI-powered **YouTube Knowledge Assistant** built using **Google Gemini 2.5 Flash** and deployed as a **Telegram Bot**.

The system converts long YouTube videos into an **interactive AI assistant** capable of:
- Generating structured summaries
- Answering contextual questions
- Retrieving knowledge directly from video transcripts

This project demonstrates a **Retrieval-Augmented Generation (RAG)** architecture integrated with real-world APIs and scalable backend design.

---

#  Project Overview

Modern video content is long and difficult to revisit for specific information.

This system transforms YouTube videos into searchable knowledge by:

1. Extracting transcripts
2. Processing content using LLMs
3. Structuring summaries
4. Enabling intelligent Q&A interaction

Users simply send a YouTube link to Telegram and interact with the video conversationally.

---

#  System Architecture

## High-Level Architecture


User (Telegram)
â”‚
â–¼
Telegram Bot Interface
â”‚
â–¼
Message Handler Layer
â”‚
â–¼
Processing Pipeline
â”œâ”€â”€ URL Validation
â”œâ”€â”€ Video ID Extraction
â”œâ”€â”€ Transcript Fetching
â”œâ”€â”€ Chunk Generation
â”œâ”€â”€ AI Summarization
â””â”€â”€ Context Retrieval
â”‚
â–¼
Gemini 2.5 Flash LLM
â”‚
â–¼
MongoDB Storage
â”‚
â–¼
AI Response â†’ Telegram User


---

# âš™ï¸ Core Architecture Design

The project follows a **modular layered architecture**.


Interface Layer
â†“
Controller Layer
â†“
Core AI Engine
â†“
Service Integrations
â†“
Data Storage


---

#  Repository Structure


YouTube-AI-Assistant---Telegram-Bot/
â”‚
â”œâ”€â”€ bot/
â”‚ â”œâ”€â”€ telegram_bot.py # Bot initialization & polling
â”‚ â”œâ”€â”€ handlers.py # Message routing logic
â”‚ â””â”€â”€ commands.py # Telegram commands
â”‚
â”œâ”€â”€ core/
â”‚ â”œâ”€â”€ transcript.py # YouTube transcript extraction
â”‚ â”œâ”€â”€ summarizer.py # Hierarchical summarization
â”‚ â”œâ”€â”€ qa_engine.py # Question answering engine
â”‚ â””â”€â”€ prompts.py # LLM prompt templates
â”‚
â”œâ”€â”€ services/
â”‚ â”œâ”€â”€ llm_service.py # Gemini model interaction
â”‚ â””â”€â”€ youtube_service.py # Video processing service
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ mongo.py # MongoDB connection
â”‚
â”œâ”€â”€ utils/
â”‚ â”œâ”€â”€ logger.py
â”‚ â”œâ”€â”€ helpers.py
â”‚ â”œâ”€â”€ validators.py
â”‚ â””â”€â”€ exceptions.py
â”‚
â”œâ”€â”€ config/
â”‚ â””â”€â”€ settings.py # Environment configuration
â”‚
â”œâ”€â”€ logs/
â”œâ”€â”€ main.py # Application entry point
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


---

#  Complete Processing Pipeline

## Step 1 â€” User Interaction
User sends a YouTube link through Telegram.


https://youtu.be/video_id


---

## Step 2 â€” Video Processing
System performs:

- URL validation
- Video ID extraction
- Transcript retrieval

Using:

youtube-transcript-api


---

## Step 3 â€” Transcript Processing

Transcript is divided into chunks to optimize LLM reasoning.

Why chunking?

âœ” Prevent token overflow  
âœ” Faster inference  
âœ” Better summarization quality  

---

## Step 4 â€” AI Summarization (Gemini 2.5 Flash)

Hierarchical summarization pipeline:


Transcript
â†“
Chunk Summaries
â†“
Merged Context
â†“
Final Structured Summary


Gemini Flash enables:
- Long context reasoning
- Fast responses
- Cost-efficient processing

---

## Step 5 â€” Storage Layer

Processed data stored in MongoDB:


Video ID
Transcript
Summary
User Session


Benefits:
- Faster repeated queries
- Persistent memory
- Multi-user scalability

---

## Step 6 â€” Question Answering (RAG)

When a user asks a question:


User Question
â†“
Relevant Transcript Retrieval
â†“
Context Injection
â†“
Gemini Reasoning
â†“
Grounded Answer


The model answers **strictly from transcript context**, reducing hallucinations.

---

#  AI Model Architecture

## Model Used

Google Gemini 2.5 Flash


### Why Gemini Flash?
- Large context window
- High reasoning speed
- Ideal for transcript analysis
- Efficient summarization

---

## Prompt Engineering Strategy

The system uses structured prompts:

- Summary Prompt
- Context QA Prompt
- Instruction-based grounding

Ensures:
 factual responses  
 contextual accuracy  
 controlled outputs  

---

# ğŸ›  Technology Stack

| Layer | Technology |
|------|------------|
| Interface | Telegram Bot API |
| Backend | Python |
| LLM | Google Gemini 2.5 Flash |
| Database | MongoDB Atlas |
| Transcript Engine | youtube-transcript-api |
| API Framework | FastAPI |
| Logging | Python Logging |
| Retrieval | Chunk-based RAG |

---

#  Environment Setup

Create `.env`


TELEGRAM_TOKEN=
GOOGLE_API_KEY=
LLM_PROVIDER=google
MODEL_NAME=gemini-2.5-flash
MONGO_URI=
LOG_LEVEL=INFO


---

#  Installation Guide

## 1 Clone Repository

```bash
git clone https://github.com/rajtharani77/YouTube-AI-Assistant---Telegram-Bot.git
cd YouTube-AI-Assistant---Telegram-Bot
2 Create Virtual Environment
python -m venv .venv

Activate:

Windows

.venv\Scripts\activate

Linux/Mac

source .venv/bin/activate
3 Install Dependencies
pip install -r requirements.txt
4 Run Application
python main.py
5 Start Using Bot

Open Telegram â†’ search your bot â†’ send a YouTube link.

ğŸ’¬ Example Workflow
Input
https://youtu.be/example
Bot Output

Video Summary

Key Insights

Ask Questions
Q. What is constant time complexity?
A. Bot answers using video knowledge.

Engineering Highlights

Modular backend architecture
Retrieval-Augmented Generation
Hierarchical summarization
API abstraction layer
Poduction-ready logging
Scalable database integration

Future Improvements

Vector embeddings (FAISS)
Multi-video knowledge base
Web dashboard

 Author
Raj Tharani
GitHub: https://github.com/rajtharani77

ğŸ“œ License

MIT License
